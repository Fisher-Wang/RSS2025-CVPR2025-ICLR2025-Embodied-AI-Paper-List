# CVPR2025-ICLR2025-Embodied-AI-Paper-List
ðŸ”¥CVPR2025 &amp; ICLR2025 Embodied AI Paper List  Resources

## ðŸ“– Table of Contents
- [ðŸ“– Table of Contents](#-table-of-contents)
  - [Vision-Language-Action Models](#vla)
  - [Policies](#policy)
  - [Planning](#planning)
  - [3D Vision](#3dv)
  - [Sim-to-real &amp; Real-to-sim](#r2s)
  - [Benchmark &amp; Dataset](#dataset)


## Vision-Language-Action Models
- **LLaVA-Critic**: Learning to Evaluate Multimodal Models [Paper](https://arxiv.org/abs/2410.02712) [Page](https://llava-vl.github.io/blog/2024-10-03-llava-critic/)
- **VLA-Explorer**: Unifying Vision, Language, and Action for Autonomous Agents [Paper](#) [Page](#)
- A Data-Centric Revisit of Pre-Trained Vision Models for Robot Learning [Paper](https://arxiv.org/abs/2503.06960) [Page](https://github.com/CVMI-Lab/SlotMIM)
- **Think Small, Act Big**: Primitive Prompt Learning for Lifelong Robot Manipulation[Paper](#) [Page](#)
- **Phoenix**: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction [Paper](#) [Page](#)
## Policies
- **KStar Diffuser**: Spatial-Temporal Graph Diffusion Policy with Kinematics Modeling for Bimanual Robotic Manipulation [Paper](https://arxiv.org/abs/2503.10743)
- **RoboPEPP**: Vision-Based Robot Pose and Joint Angle Estimation through Embedding Predictive Pre-Training [Paper](https://arxiv.org/abs/2411.17662)
- **OmniManip**: Towards General Robotic Manipulation via Object-Centric Interaction Primitives as Spatial Constraints [Paper](https://arxiv.org/abs/2501.03841)

## Humanoid &amp; Legged Robot
- Let Humanoid Robots Go Hiking! Integrative Skill Development over Complex Trails[Page](https://lego-h-humanoidrobothiking.github.io/)
## Planning
- **PlanFormer**: Transformer-based Planning for Embodied Navigation [Paper](#) [Page](#)
- **Hierarchical Planning in Embodied AI**: Learning Multi-level Strategies for Long-Horizon Tasks [Paper](#) [Page](#)

## 3D Vision
- **3D-SceneLearner**: Learning Robust 3D Representations for Embodied Agents [Paper](#) [Page](#)
- **RealTime3D**: Fast 3D Reconstruction and Scene Understanding for Real-World Interaction [Paper](#) 
[Page](#)
- **VidBot**: Learning Generalizable 3D Actions from In-the-Wild 2D Human Videos for Zero-Shot Robotic Manipulation[Paper](https://arxiv.org/abs/2503.07135) [Page](#)
- **AutoURDF**: Unsupervised Robot Modeling from Point Cloud Frames Using Cluster Registration[Paper](https://arxiv.org/abs/2412.05507) [Page](https://github.com/jl6017/AutoURDF)

## Sim-to-real & Real-to-sim
- **Sim2Real Bridge**: Reducing the Reality Gap in Robotic Control via Domain Adaptation [Paper](#) [Page](#)
- **Real2Sim Dynamics**: Leveraging Real-World Data to Enhance Simulation Fidelity [Paper](#) [Page](#)

## Benchmark & Dataset
- **EmbodiedAI Benchmark**: A Comprehensive Dataset for Evaluating Embodied Agents [Paper](#) [Page](#)
- **Multi-Modal Indoor Navigation Dataset**: Real-world Scenarios for Embodied AI [Paper](#) [Page](#)
- **RoboTwin**: Dual-Arm Robot Benchmark with Generative Digital Twins (early version)[Paper](https://arxiv.org/abs/2409.02920) [Page](https://robotwin-benchmark.github.io/early-version/)
