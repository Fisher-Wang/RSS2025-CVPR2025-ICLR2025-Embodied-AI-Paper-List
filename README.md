# CVPR2025-ICLR2025-Embodied-AI-Paper-List
ðŸ”¥CVPR2025 &amp; ICLR2025 Embodied AI Paper List  Resources

## ðŸ“– Table of Contents
- [ðŸ“– Table of Contents](#-table-of-contents)
  - [Vision-Language-Action Models](#vla)
  - [Policies](#policy)
  - [Planning](#planning)
  - [3D Vision](#3dv)
  - [Sim-to-real &amp; Real-to-sim](#r2s)
  - [Benchmark &amp; Dataset](#dataset)


## Vision-Language-Action Models
<<<<<<< HEAD
- **LLaVA-Critic**: Learning to Evaluate Multimodal Models [Paper](https://arxiv.org/abs/2410.02712) [Page](https://llava-vl.github.io/blog/2024-10-03-llava-critic/)
- **VLA-Explorer**: Unifying Vision, Language, and Action for Autonomous Agents [Paper](#) [Page](#)
- A Data-Centric Revisit of Pre-Trained Vision Models for Robot Learning [Paper](https://arxiv.org/abs/2503.06960) [Page](https://github.com/CVMI-Lab/SlotMIM)
- **Think Small, Act Big**: Primitive Prompt Learning for Lifelong Robot Manipulation[Paper](#) [Page](#)
- **Phoenix**: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction [Paper](#) [Page](#)
=======
- **OmniManip**: Towards General Robotic Manipulation via Object-Centric Interaction Primitives as Spatial Constraints [Paper](https://arxiv.org/abs/2501.03841)
- Mitigating the Human-Robot Domain Discrepancy in Visual Pre-training for Robotic Manipulation [Paper](https://arxiv.org/abs/2406.14235)
- Object-Centric Prompt-Driven Vision-Language-Action Model for Robotic Manipulation [Paper](https://cvpr.thecvf.com/virtual/2025/poster/34522)
- Robotic Visual Instruction
- **RoboGround**: Robot Manipulation with Grounded Vision-Language Priors

>>>>>>> b5d3b97de6b20b1f7f76fa3fce6446e85022baa0
## Policies
- **KStar Diffuser**: Spatial-Temporal Graph Diffusion Policy with Kinematics Modeling for Bimanual Robotic Manipulation [Paper](https://arxiv.org/abs/2503.10743)
- **RoboPEPP**: Vision-Based Robot Pose and Joint Angle Estimation through Embedding Predictive Pre-Training [Paper](https://arxiv.org/abs/2411.17662)
- **Lift3D Policy**: Lifting 2D Foundation Models for Robust 3D Robotic Manipulation [Paper](https://arxiv.org/abs/2411.18623) [Page](https://lift3d-web.github.io/)
- **PDFactor**: Learning Tri-Perspective View Policy Diffusion Field for Multi-Task Robotic Manipulation [Paper](https://cvpr.thecvf.com/virtual/2025/poster/33943)
- **Two by Two**: Learning Cross-Task Pairwise Objects Assembly for Generalizable Robot Manipulation
- **FlowRAM**: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation [Paper](https://cvpr.thecvf.com/virtual/2025/poster/33579)

## Grasp
- **UniGraspTransformer**: Simplified Policy Distillation for Scalable Dexterous Robotic Grasping [Paper](https://arxiv.org/abs/2412.02699) [Page](https://dexhand.github.io/UniGraspTransformer/)
- **DexGrasp Anything**: Towards Universal Robotic Dexterous Grasping with Physics Awareness [Paper](https://arxiv.org/abs/2503.08257)
- **ZeroGrasp**: Zero-Shot Shape Reconstruction Enabled Robotic Grasping [Paper](https://cvpr.thecvf.com/virtual/2025/poster/32440)

## Humanoid &amp; Legged Robot
<<<<<<< HEAD
- Let Humanoid Robots Go Hiking! Integrative Skill Development over Complex Trails[Page](https://lego-h-humanoidrobothiking.github.io/)
## Planning
- **PlanFormer**: Transformer-based Planning for Embodied Navigation [Paper](#) [Page](#)
- **Hierarchical Planning in Embodied AI**: Learning Multi-level Strategies for Long-Horizon Tasks [Paper](#) [Page](#)

## 3D Vision
- **3D-SceneLearner**: Learning Robust 3D Representations for Embodied Agents [Paper](#) [Page](#)
- **RealTime3D**: Fast 3D Reconstruction and Scene Understanding for Real-World Interaction [Paper](#) 
[Page](#)
- **VidBot**: Learning Generalizable 3D Actions from In-the-Wild 2D Human Videos for Zero-Shot Robotic Manipulation[Paper](https://arxiv.org/abs/2503.07135) [Page](#)
- **AutoURDF**: Unsupervised Robot Modeling from Point Cloud Frames Using Cluster Registration[Paper](https://arxiv.org/abs/2412.05507) [Page](https://github.com/jl6017/AutoURDF)
=======
- **MobileH2R**: Learning Generalizable Human to Mobile Robot Handover Exclusively from Scalable and Diverse Synthetic Data [Paper](https://arxiv.org/abs/2501.04595)

## Planning &amp; Reasoning
- **RoboBrain**: A Unified Brain Model for Robotic Manipulation from Abstract to Concrete [Paper](https://arxiv.org/abs/2502.21257)
- **PhysVLM**: Enabling Visual Language Models to Understand Robotic Physical Reachability [Paper](https://arxiv.org/abs/2503.08481)
- **RoboSpatial**: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics [Paper](https://arxiv.org/abs/2411.16537)
- **Tartan IMU**: A Light Foundation Model for Inertial Positioning in Robotics [Paper](https://cvpr.thecvf.com/virtual/2025/poster/33873)
- **Code-as-Monitor**: Constraint-aware Visual Programming for Reactive and Proactive Robotic Failure Detection [Paper](https://arxiv.org/abs/2412.04455) [Page](https://zhoues.github.io/Code-as-Monitor/)

## Video
- **Roger**: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation
>>>>>>> b5d3b97de6b20b1f7f76fa3fce6446e85022baa0

## 3D Vision
- **Prof. Robot**: Differentiable Robot Rendering Without Static and Self-Collisions [Paper](https://arxiv.org/abs/2503.11269)
- **3D-MVP**: 3D Multiview Pretraining for Robotic Manipulation [Paper](https://arxiv.org/abs/2406.18158)

## Benchmark & Dataset
<<<<<<< HEAD
- **EmbodiedAI Benchmark**: A Comprehensive Dataset for Evaluating Embodied Agents [Paper](#) [Page](#)
- **Multi-Modal Indoor Navigation Dataset**: Real-world Scenarios for Embodied AI [Paper](#) [Page](#)
- **RoboTwin**: Dual-Arm Robot Benchmark with Generative Digital Twins (early version)[Paper](https://arxiv.org/abs/2409.02920) [Page](https://robotwin-benchmark.github.io/early-version/)
=======
- Pixel-aligned RGB-NIR Stereo Imaging and Dataset for Robot Vision [Paper](https://arxiv.org/abs/2411.18025)
- **RoboSense**: Large-scale Dataset and Benchmark for Egocentric Robot Perception and Navigation in Crowded and Unstructured Environments [Paper](https://arxiv.org/abs/2408.15503)
>>>>>>> b5d3b97de6b20b1f7f76fa3fce6446e85022baa0
